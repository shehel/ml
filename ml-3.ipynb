{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaleData(dataFrame,flag,tLabel):\n",
    "    df = dataFrame.copy()\n",
    "\n",
    "    for var in df.drop(tLabel,axis=1):\n",
    "        mean = df[var].mean()\n",
    "        std = df[var].std()\n",
    "        l1 = (df[var].abs()).sum()\n",
    "\n",
    "        if(flag == 1):\n",
    "            df[var] = (df[var]-mean)/std\n",
    "        else:\n",
    "            df[var] = df[var]/l1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
      "1  -1.523680 -1.797414 -1.965590 -0.995955 -0.533063 -0.836769 -1.031712   \n",
      "2  -1.857204 -0.643057 -0.899238 -0.995955 -0.533063 -0.836769 -1.031712   \n",
      "3  -1.468157 -1.961526  1.233468 -0.995955 -0.533063 -0.836769  0.378996   \n",
      "4  -2.025981 -0.720349 -0.899238 -0.995955 -0.533063 -0.836769 -1.031712   \n",
      "5  -0.452342 -0.406493 -0.366061 -0.995955 -0.533063 -0.836769 -1.031712   \n",
      "6  -1.901925 -0.833573 -1.965590 -0.995955 -0.533063 -0.836769 -1.031712   \n",
      "8  -0.499235 -0.181701 -0.899238  1.001211 -0.533063 -0.836769 -1.031712   \n",
      "11 -0.852131 -0.046097  0.033821 -0.995955 -0.533063 -0.836769 -1.031712   \n",
      "12 -2.141144 -0.057546 -0.232767  0.816796 -0.533063 -0.836769 -1.031712   \n",
      "13  0.241382 -1.265727 -0.232767 -0.995955 -0.533063 -0.273880  0.378996   \n",
      "14  0.131626 -1.317410  0.300409 -0.995955 -0.533063 -0.836769  0.378996   \n",
      "16  0.183220 -1.185595  0.167115 -0.995955 -0.533063 -0.836769 -1.031712   \n",
      "17 -1.391454 -0.231000  0.700291  0.801223 -0.533063 -0.273880  0.378996   \n",
      "18  0.784647  0.048786  0.167115 -0.995955 -0.533063  0.418185 -1.031712   \n",
      "19 -1.509436 -0.752080 -3.165237 -0.995955 -0.533063 -0.836769 -1.031712   \n",
      "20 -0.910332  0.418101  0.700291  1.084127 -0.533063 -0.836769 -1.031712   \n",
      "21 -0.133664 -0.433786 -0.765944 -0.995955 -0.533063 -0.836769 -1.031712   \n",
      "23 -1.495439 -0.525026 -0.765944 -0.594367 -0.533063 -0.836769 -1.031712   \n",
      "24  0.376808 -0.366205 -0.232767  0.250616 -0.533063  0.994376  0.378996   \n",
      "27 -0.644354  0.196272  0.033821 -0.995955 -0.533063 -0.417141  0.378996   \n",
      "29 -0.219875 -1.043130  0.300409  0.103647 -0.533063  0.187754  0.378996   \n",
      "30  0.882151 -0.525026  0.033821 -0.995955 -0.533063  1.309021 -1.031712   \n",
      "31 -0.827556  0.973690  0.033821  1.292291 -0.533063 -0.417141 -1.031712   \n",
      "33 -0.030685 -1.235318  0.833585  0.816796 -0.533063 -0.836769 -1.031712   \n",
      "35 -1.065147 -0.858651 -0.232767 -0.995955 -0.533063 -0.417141 -1.031712   \n",
      "37  0.088216  0.065093  1.100174 -0.444954 -0.533063  1.336749  1.789705   \n",
      "38 -0.688937 -2.625262 -0.099473 -0.995955 -0.533063 -0.836769  0.378996   \n",
      "39  1.084402  0.963130  0.433703  0.889742  1.847952  1.461222  0.378996   \n",
      "40 -0.415249 -1.286248 -1.165826  0.590750 -0.533063  0.036898  0.378996   \n",
      "41 -0.557638 -1.015761 -0.632650 -0.995955 -0.533063 -0.836769  3.200414   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "58 -0.683860  0.290756 -2.098884  0.923488 -0.533063 -0.836769 -1.031712   \n",
      "59 -0.620613  1.158450  0.700291  0.250616 -0.533063 -0.836769  0.378996   \n",
      "60 -0.202991  0.472310 -0.499355  0.835776 -0.533063 -0.836769  0.378996   \n",
      "61 -0.688937  1.885004  1.100174  1.540569 -0.533063 -0.836769 -1.031712   \n",
      "63  1.176749 -0.212376  0.966879 -0.995955 -0.533063  1.265298  3.200414   \n",
      "67  0.570888  0.529496  0.433703  1.169641 -0.533063  1.096538  0.378996   \n",
      "68  0.712096  0.891327  0.966879  1.527773 -0.533063 -0.154619  0.378996   \n",
      "69 -1.416218  1.641708  0.566997 -0.995955 -0.533063 -0.836769 -1.031712   \n",
      "70 -0.096226  2.421891  0.966879  1.540569 -0.533063 -0.417141  0.378996   \n",
      "71  0.443097 -0.069059 -0.632650 -0.995955  1.847952  1.096538  0.378996   \n",
      "72 -0.123509 -0.598016  1.633350  1.146281 -0.533063 -0.836769  0.378996   \n",
      "75  1.356629  0.467845  0.566997 -0.995955  1.847952  1.516165  0.378996   \n",
      "76  1.470830 -0.760088  0.433703 -0.083854  1.847952  1.880849  0.378996   \n",
      "77  0.561250  1.694671  0.966879  1.401165 -0.533063  0.510431  0.378996   \n",
      "78  0.985172  1.528903  1.766644  1.540569 -0.533063 -0.836769  0.378996   \n",
      "79  1.074215 -0.092276  0.566997 -0.995955  1.847952  1.997666  0.378996   \n",
      "81  0.124243 -1.166032  0.167115  0.333532 -0.533063  0.312226  0.378996   \n",
      "82  0.965857 -0.320162 -1.032532  0.250616 -0.533063  1.814391  0.378996   \n",
      "83  1.045811  0.551082  1.633350 -0.409299  1.847952  0.552438  0.378996   \n",
      "85  0.200271  0.175827 -0.632650  1.109671 -0.533063  0.731854  0.378996   \n",
      "86  1.600976 -0.224774 -0.099473 -0.995955  1.847952  1.814391  0.378996   \n",
      "87  0.571952  0.221551 -0.899238  1.070988 -0.533063 -0.836769 -1.031712   \n",
      "88  0.336526 -0.539424 -0.366061 -0.995955  1.847952  0.367170  0.378996   \n",
      "89  1.202409  2.291109  0.033821 -0.995955  1.847952  1.911893  0.378996   \n",
      "90  0.200271  0.144780  1.500056  0.590750  1.847952  0.731854  0.378996   \n",
      "91  1.555621  0.998130  0.433703 -0.995955 -0.533063 -0.836769 -1.031712   \n",
      "92  0.981346  0.107969 -0.499355  0.872223  1.847952 -0.836769  0.378996   \n",
      "93  1.220657  0.525153  0.433703 -0.995955  1.847952  1.096538  0.378996   \n",
      "94  2.017972  0.568193 -2.765355 -0.995955  1.847952  1.701433  0.378996   \n",
      "96  1.262743  0.310118  0.433703  1.015748  1.847952  1.265298  0.378996   \n",
      "\n",
      "       pgg45      lpsa  \n",
      "1  -0.896487 -0.430783  \n",
      "2  -0.896487 -0.162519  \n",
      "3  -0.213934 -0.162519  \n",
      "4  -0.896487 -0.162519  \n",
      "5  -0.896487  0.371564  \n",
      "6  -0.896487  0.765468  \n",
      "8  -0.896487  0.854415  \n",
      "11 -0.896487  1.266948  \n",
      "12 -0.896487  1.266948  \n",
      "13  0.127342  1.266948  \n",
      "14 -0.725849  1.348073  \n",
      "16 -0.896487  1.446919  \n",
      "17  0.127342  1.470176  \n",
      "18 -0.896487  1.492904  \n",
      "19 -0.896487  1.558145  \n",
      "20 -0.896487  1.599388  \n",
      "21 -0.896487  1.638997  \n",
      "23 -0.896487  1.695616  \n",
      "24  1.151171  1.713798  \n",
      "27  1.492447  1.800058  \n",
      "29  1.833724  1.848455  \n",
      "30 -0.896487  1.894617  \n",
      "31 -0.896487  1.924249  \n",
      "33 -0.896487  2.008214  \n",
      "35 -0.896487  2.047693  \n",
      "37 -0.384573  2.157559  \n",
      "38 -0.384573  2.191654  \n",
      "39  0.297980  2.213754  \n",
      "40 -0.725849  2.277267  \n",
      "41  1.833724  2.297573  \n",
      "..       ...       ...  \n",
      "58 -0.896487  2.794228  \n",
      "59 -0.213934  2.806386  \n",
      "60  0.468618  2.812410  \n",
      "61 -0.896487  2.841998  \n",
      "63  2.345638  2.853592  \n",
      "67  1.492447  2.920470  \n",
      "68 -0.555211  2.962692  \n",
      "69 -0.896487  2.962692  \n",
      "70 -0.725849  2.972975  \n",
      "71  1.151171  3.013081  \n",
      "72 -0.043296  3.037354  \n",
      "75 -0.213934  3.275256  \n",
      "76  0.809895  3.337547  \n",
      "77  1.151171  3.392829  \n",
      "78 -0.555211  3.435599  \n",
      "79  1.492447  3.457893  \n",
      "81  0.468618  3.516013  \n",
      "82  1.151171  3.530763  \n",
      "83  0.127342  3.565298  \n",
      "85  0.127342  3.587677  \n",
      "86  1.151171  3.630986  \n",
      "87 -0.896487  3.680091  \n",
      "88  0.127342  3.712352  \n",
      "89  1.151171  3.984344  \n",
      "90  1.663086  3.993603  \n",
      "91 -0.896487  4.029806  \n",
      "92 -0.384573  4.129551  \n",
      "93  1.151171  4.385147  \n",
      "94  0.468618  4.684443  \n",
      "96  1.833724  5.477509  \n",
      "\n",
      "[67 rows x 9 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFkCAYAAACuFXjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAOgSCwBA1/8DBAe+bZJxNlwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee13c9a5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('prostate.data', header = 0, delim_whitespace=True)\n",
    "#print (df)\n",
    "dfTrain = df[df.train == 'T']\n",
    "dfTest = df[df.train == 'F']\n",
    "dfTrain = dfTrain.drop('train', 1)\n",
    "dfTest = dfTest.drop('train', 1)\n",
    "\n",
    "dfScTrain = scaleData(dfTrain, 1, 'lpsa')\n",
    "dfScTest = scaleData(dfTest, 1, 'lpsa')\n",
    "#dfScTrain = dfTrain.copy()\n",
    "#dfScTest = dfTest.copy()\n",
    "\n",
    "print (dfScTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.51 [[ 0.63591522  0.28854502 -0.11881213  0.20473644  0.291185   -0.19058621\n",
      "   0.00588271  0.22138017]]\n"
     ]
    }
   ],
   "source": [
    "ridge = sk.RidgeCV(alphas = np.arange(-20,20,0.01))\n",
    "ridge.fit(dfScTrain.iloc[:, 0:8], dfScTrain.iloc[:, 8:9])\n",
    "print (ridge.alpha_, ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 [ 0.57487434  0.2300614  -0.          0.10508914  0.17173396  0.          0.\n",
      "  0.0653523 ]\n",
      "LassoCV(alphas=array([-20.  , -19.95, ...,  19.9 ,  19.95]), copy_X=True,\n",
      "    cv=None, eps=0.001, fit_intercept=True, max_iter=1000, n_alphas=100,\n",
      "    n_jobs=1, normalize=False, positive=False, precompute='auto',\n",
      "    random_state=None, selection='cyclic', tol=0.0001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso = sk.LassoCV(alphas=np.arange(-20,20,0.05))\n",
    "fit = lasso.fit(dfScTrain.iloc[:, 0:8], dfScTrain.iloc[:, 8:9].values.ravel())\n",
    "print (lasso.alpha_, lasso.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71640701  0.2926424  -0.14254963  0.2120076   0.30961953 -0.28900562\n",
      "  -0.02091352  0.27734595]]\n"
     ]
    }
   ],
   "source": [
    "linear = sk.LinearRegression()\n",
    "linear.fit(dfScTrain.iloc[:, 0:8], dfScTrain.iloc[:, 8:9])\n",
    "print (linear.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.524107605502\n"
     ]
    }
   ],
   "source": [
    "#PREDICTIN DOOM\n",
    "predictedSet = (ridge.predict(dfScTest.iloc[:, 0:8]))\n",
    "totalLoss = 0\n",
    "for index, list in enumerate(predictedSet):\n",
    "    loss = (list[0] -  dfScTest['lpsa'].iloc[index]) ** 2 \n",
    "    totalLoss = totalLoss + loss    \n",
    "print (totalLoss/len(predictedSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.549194139132\n"
     ]
    }
   ],
   "source": [
    "predictedSet = (linear.predict(dfScTest.iloc[:, 0:8]))\n",
    "totalLoss = 0\n",
    "for index, list in enumerate(predictedSet):\n",
    "    loss = (list[0] -  dfScTest['lpsa'].iloc[index]) ** 2 \n",
    "    totalLoss = totalLoss + loss    \n",
    "print (totalLoss/len(predictedSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.454982788477\n"
     ]
    }
   ],
   "source": [
    "predictedSet = (lasso.predict(dfScTest.iloc[:, 0:8]))\n",
    "totalLoss = 0\n",
    "for index, list in enumerate(predictedSet):\n",
    "    loss = (list -  dfScTest['lpsa'].iloc[index]) ** 2 \n",
    "    totalLoss = totalLoss + loss    \n",
    "print (totalLoss/len(predictedSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
      "7  -0.669858 -0.537547  0.298149  0.311748 -0.491596 -0.908984 -1.051077   \n",
      "9  -2.130049 -0.318246 -2.115437 -1.074047 -0.491596 -0.908984 -1.051077   \n",
      "10 -1.165710 -1.298473  0.156173 -1.074047 -0.491596 -0.908984 -1.051077   \n",
      "15 -0.217622 -0.642225 -0.695681 -1.074047 -0.491596 -0.232933  0.262769   \n",
      "22  0.605487 -0.446076 -0.269754  0.906906 -0.491596  1.025657  0.262769   \n",
      "25 -1.009322  0.106761  1.008027  0.993194 -0.491596 -0.908984 -1.051077   \n",
      "26  0.014810 -1.697187  0.866051  0.093590 -0.491596 -0.908984 -1.051077   \n",
      "28 -1.767289  0.766678  0.724076  1.143487 -0.491596 -0.908984  0.262769   \n",
      "32 -1.205089  0.562165  0.440125  1.066144 -0.491596 -0.908984 -1.051077   \n",
      "34 -1.371368 -1.221634 -1.121608 -1.074047 -0.491596 -0.908984 -1.051077   \n",
      "36 -0.118878  1.610341  0.298149  1.389203 -0.491596 -0.908984  0.262769   \n",
      "42  0.010260  0.157307  0.866051 -1.074047 -0.491596 -0.908984  0.262769   \n",
      "44  0.327973  0.869464 -0.127778 -1.074047 -0.491596  0.645614  0.262769   \n",
      "48 -0.258928  1.328783  0.866051  1.072410 -0.491596 -0.232933  0.262769   \n",
      "49  0.303045 -0.456116 -2.683340 -1.074047 -0.491596 -0.908984 -1.051077   \n",
      "50 -0.203288 -0.223156  1.150003  0.836942 -0.491596 -0.493109 -1.051077   \n",
      "53 -0.886269 -0.005460  0.298149  0.919467 -0.491596  0.106378  0.262769   \n",
      "54  0.670892  1.615735  0.866051  1.108860 -0.491596  1.095594  0.262769   \n",
      "55  1.661158 -0.396328 -0.411729 -1.074047 -0.491596 -0.908984  0.262769   \n",
      "57 -0.440854 -2.559593 -2.115437 -1.074047 -0.491596  0.426170  0.262769   \n",
      "62  0.545851  0.280401  0.156173  1.007042  1.966384  1.422913  0.262769   \n",
      "64  0.581821  0.936267  0.582100  1.276260  1.966384  1.564893  0.262769   \n",
      "65  0.618927 -0.040766  0.298149 -1.074047 -0.491596 -0.908984 -1.051077   \n",
      "66  0.026092  0.667786 -0.127778  0.800966 -0.491596 -0.232933  0.262769   \n",
      "73 -0.208996  0.631743  1.008027 -1.074047  1.966384  0.229738  0.262769   \n",
      "74  0.392995 -1.324487 -0.269754  0.189243  1.966384  0.905789  2.890461   \n",
      "80  1.300232  0.624488  0.156173 -1.074047 -0.491596  0.334750  0.262769   \n",
      "84  1.201983  0.674948  0.440125  0.657910 -0.491596  1.309466  2.890461   \n",
      "95  1.423715 -0.794540 -1.405559 -1.074047  1.966384  1.815103  0.262769   \n",
      "97  1.968280  1.128970  0.866051  0.189243  1.966384  2.126636  0.262769   \n",
      "\n",
      "       pgg45      lpsa  \n",
      "7  -0.789408  0.765468  \n",
      "9  -0.789408  1.047319  \n",
      "10 -0.789408  1.047319  \n",
      "15 -0.593687  1.398717  \n",
      "22 -0.006524  1.658228  \n",
      "25 -0.789408  1.731656  \n",
      "26 -0.789408  1.766442  \n",
      "28 -0.006524  1.816452  \n",
      "32 -0.789408  2.008214  \n",
      "34 -0.789408  2.021548  \n",
      "36 -0.593687  2.085672  \n",
      "42 -0.397966  2.307573  \n",
      "44 -0.554543  2.374906  \n",
      "48  0.776360  2.568788  \n",
      "49 -0.789408  2.591516  \n",
      "50 -0.789408  2.591516  \n",
      "53  1.950687  2.684440  \n",
      "54  0.776360  2.691243  \n",
      "55 -0.593687  2.704711  \n",
      "57 -0.632832  2.788093  \n",
      "62  0.776360  2.853592  \n",
      "64  1.559245  2.882004  \n",
      "65 -0.789408  2.882004  \n",
      "66 -0.006524  2.887590  \n",
      "73 -0.006524  3.056357  \n",
      "74  2.733572  3.075006  \n",
      "80  1.167803  3.513037  \n",
      "84  1.950687  3.570940  \n",
      "95 -0.397966  5.143124  \n",
      "97 -0.006524  5.582932  \n",
      "[ 2.23608061]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
